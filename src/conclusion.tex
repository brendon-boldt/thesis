\chapter{Conclusion}
\unskip\label{ch:conclusion}

\cmt{Maybe start out with picking up on the theme of order and chaos?}

\cmt{Q1: Why does advancing science and engineering with deep learning-based emergent language require principled, environment-agnostic analytical algorithms?}

% D: findings, broadly
% Y: distill everything you learned in this process and things

\cmt{A1: Patterns in emergent language can only be seen at scale, which requires automated ways of quantifying different properties of emergent language.}
\cmt{Do I have evidence for this?}

\cmt{The output of deep learning-based emergent language simulations can easily be garbage.  By the principle, of garbage in, garbage out, the outputs of the analytical tools presented here can also be garbage.}
\cmt{The output of the methods presented here are almost never meaningful by themselves and need to form a larger part of an analytical process (e.g., ablations).}

% D: "now that I solved these problems, what does mean? What has changed in the field effectively on account of my work? What comes next? What work does this thesis make possible?"

\cmt{What is now possible?}
\cmt{More directly comparing emergent languages.}
\cmt{Capturing the neural network's perspective of similarity to human language (XferBench).}
\cmt{Ascending to higher levels of linguistic analysis on emergent languages.}
\cmt{Meta-meta: what does the aforementioned make possible?}


% Y: what things do I have a unique perspective on

\cmt{If you are not careful, emergent languages will always let you down and be less interesting than you think.  Instead, you should adopt a sober pessimism that the emergent languages are not showing interesting patterns and create tests that all but guarantee the pattern you are looking for is present (not proxies).}


% Y: for a new student starting: what are the most important things for them to know

\cmt{Emergent language is difficult to interpret, and it if you do not respect this you will either rush through analysis with subpar findings or spend all of your time analyzing a non-representative set of languages.}
\cmt{Mention something here about the pitfall of search space in emergent language.  Probably needs to be combined with the scaling up comment.}


% Y: what should this hypothetical new student start with

\cmt{Even with the tools to find order in the chaos, there is still a lot of chaos. As such, it might be more fruitful to start with more classical simulations and generalize them using deep learning.}
\cmt{Future work would really have to upgrade the tools; this thesis has practically demonstrated what kind of tools are needed, but they are unrefined.}
\cmt{Give concrete examples, expanding ELCC (depth and breadth), scale up XferBench, make CSAR not greedy.}

% misc

\cmt{Answer some of the questions from the prologue.}
\cmt{How does this work relate to order and chaos?}
\cmt{Yes, we need to move past the signalling game, but will likely not yield much fruit until we can interpret the signalling game \emph{qua} basic environment.}

\chapter*{Epilogue}
The year is 2026.
Large language models have become almost synonymous with the term ``AI'', at least in the popular lexicon.
Emergent language has maintained its niche \emph{status quo} since the time described in the Prologue, but it cannot match the optimism of ``GenAI''.
While Sutton's ``Bitter Lesson'' seems to hold more now than ever, deep reinforcement learning is often now just a method for augmenting LLMs.
This thesis has hardly mentions LLMs let alone contributes to their advancement---how are its pages still relevant, then?

These pages are still relevant because the foundational questions of linguistics are \emph{scientific} questions.
LLMs can certainly assist in answering some of these questions, but a model that merely ingests and mimics \cmt{maybe temper this statement?} human language use is limited in what it can tell us about the internal and external pressures begetting human language.
No degree of real-world utility or benchmark topping will provide the understanding that characterizes scientific questions.
The project of building high-fidelity simulations of \emph{de novo} language evolution, on the other hand, have potential to address the deeper questions of the origins of human language.
While emergent language certainly lacks the glamour of deep RL in 2018 or LLMs in 2026, so long as there are linguists inquiring into language (and the Lindy effect is on my side, here), the contributions of this thesis will have a home.


\cmt{How to touch on the fact of the engineering applications seem to be obviated?}
