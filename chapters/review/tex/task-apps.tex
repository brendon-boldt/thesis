\section{Task-Driven Applications}\label{sec:rev-task}

The task-driven applications of emergent communication center around fields of engineering such as machine learning, natural language processing, and multi-agent systems, and typically involve solving a well-defined, practical problems.
These applications have the most immediate impacts and, as such, offer some of the most convincing motivations for developing emergent communication techniques in the short term.
The primary challenges in this area come from competing against more established methods in deep learning which are continually advancing through larger and larger scales of data and compute.


\subsection{Synthetic language data}%
\label{sec:rev-synthetic}

\paragraph{Description}
In the context of deep learning, synthetic data refers to data which is generated with a computer program; this is in contrast to ``real''  or ``natural'' data which is collected from an actual system being studied.
For example, the language we find in books, conversations, speeches, etc.\@ would all be real, in this sense, whereas a corpus of sentences generated by sampling from a probabilistic context-free grammar would be synthetic.
For example, within NLP, synthetic data can be used for transfer learning \citep{Papadimitriou2020LearningMH,mirzaee-kordjamshidi-2022-transfer} and model probing \citep{lake2018generalization,zhang2022unveiling}.
Synthetic data has a number of advantages when applied to deep learning; this includes: controllability, availability in arbitrary quantities, availability in low-resource domains (e.g., endangered languages, multi-modal settings), alleviating concerns about bias, and alleviating privacy concerns (since data is not collected from humans, e.g., through surveillance).
Although synthetic data finds niche uses alongside real data in deep learning and NLP, it fails to have widespread applicability because it often does not capture the plethora of nuances and irregularities that appear in real data, that is, the ``long tail'' of the real data distribution.
In natural language, this can manifest as unnatural but valid syntactic structures, uncommon senses of words, idioms, and wordplay.

We consider all kinds of pretraining, data augmentation, analyses, and evaluation of deep learning models with emergent communication as part of this application even if it does not involve generating synthetic datasets \emph{per se}.
For example, you might use a trained emergent communication agent itself to pretrain or evaluate a model instead of generating an intermediate dataset.


\paragraph{Applicability}

Emergent communication could serve as a way to generate synthetic language data which more closely mimics the natural variation found in human language.
The distribution of patterns within natural language has a ``long tail'' insofar as a large proportion of the total mass comprises a large number of infrequent patterns, making it very difficult for something like synthetic data generated by handcrafted programs to sufficiently replicate the distribution \citep{naikthesis}.
This is illustrated by the history of NLP\@: handcrafted expert systems have been surpassed by learning-based method which can scalably leverage computing power to mine patterns from increasingly large quantities of data.
Emergent communication, rather than mining patterns directly from data, seeks to uncover linguistic and behavioral patterns which are latent in the communicative pressures of embodied multi-agent environments.
Work such as \citet{artetxe-etal-2020-cross} demonstrates that deep neural networks do learn latent, language-agnostic patterns from their training data;
  this suggests that even if an emergent language does not have a one-to-one correspondence with some particular human language, having underlying structural similarities with human language would be sufficient to still be useful.


\paragraph{Current state}
Work towards using emergent communication to generate synthetic data has been at the proof-of-concept level.
The papers in our survey (discussed below) showed that emergent communication could indeed improve the performance of neural NLP models when used for pretraining in very low-resource settings.
That being said,
  experiments only cover a narrow selection of datasets/tasks and do not rigorously compare against alternative methods (e.g., traditional synthetic data, cross-lingual transfer).
As a result, is difficult to gauge the practical impact of the proposed methods.

\citet{Li2020EmergentCP} pretrain encoder-decoder few-shot machine translation models with an emergent communication signalling game;
  in addition to finding improvements in very low-resource settings, the experiments showed that the task success rate in the emergent communication game was well-correlated with the downstream BLEU score.
\citet{downey2022learning} also tackle machine translation, but instead use an emergent communication game to fine tune a multi-modal model for unsupervised machine translation, finding that emergent communication is more effective than the back-translation baseline.
\citet{yao2022linking} take a slightly different approach by using the emergent communication game only to generate a synthetic corpus (instead of training the models directly);
  this corpus is then used to pretrain models for language modeling and image captioning tasks.
The experiments compare emergent language corpora against two baselines:
  Spanish
  and a synthetic dataset generate by sampling delimiters from a Zipfian distribution to create a hierarchical language with similar structural biases to human language (e.g., {\small\ttfamily \{<()>[]()\}}).
For the lowest data regimes, pretraining the model on emergent language corpora reliably outperforms models pretrained on the baseline datasets.
Finally, \citet{mu2023ec} use emergent communication to pretrain an instruction-following embodied control model (e.g., for controlling a robotic arm);
  the experiments showed that not only does the proposed method outperform the baseline models but also that the emergent language is more effective as training data than pre-trained, static representations derived from video demonstrations.

\paragraph{Next steps}
The first direction is thoroughly investigating the different ways emergent communication can be used for generating synthetic data.
\citet{Li2020EmergentCP} (using emergent communication agent models directly downstream) and \citet{yao2022linking} (using emergent language corpora for pretraining downstream models) take different approaches to the same task of pretraining downstream NLP models.
These approaches have different relative merits (e.g., making better use of training data versus decoupling agent architecture from downstream architecture, respectively), and there are likely more ways to approach the same problem with emergent communication.
Thus, next steps would consist of finding other promising methods of harnessing emergent communication for model pretraining and comparing these approaches on a common ground.
Determining which of the approaches is best is critical to giving emergent communication the best chance of surpassing more traditional methods model pretraining and generating synthetic data.

The second direction which can be pursed after or in parallel to the first is rigorously comparing emergent communication for pretraining neural NLP models with more established techniques like cross-lingual transfer and traditional synthetic data \citep{artetxe-etal-2020-cross}.
First and foremost, this helps to establish whether or not emergent language data can truly surpass what is already present in the field.
In particular, comparison against cross-lingual transfer should highlight how emergent language data is more available, that is, it can be attained in higher quantities with more relevance to the target language than cross-lingual data.
Comparison against traditional synthetic data could tease out exactly what properties of emergent communication make it more effective in downstream applications.
For example, emergent communication could be compared against increasingly complex synthetic languages: balanced parentheses, context-free grammars, then full-scale grammars (e.g., head-driven phrase structure grammar \citep{pollard1994head}).

Both directions would entail developing a sort of benchmark for testing the effectiveness of pretraining methods.
This would require not only finding suitable data sources and evaluation metrics, as usual, but also determining how to make the variety of methods for pretraining comparable.
For example, emergent communication is more computationally expensive than traditional synthetic data and standard NLP pretraining methods, yet it could surpass synthetic data in quality and real data in low-resource settings.
Therefore the benchmark would have to take into account data and computational requirements in addition to raw performance.


\subsection{Multi-agent communication}%
\label{sec:rev-multi-agent}
\paragraph{Description}

The area of multi-agent communication is concerned with autonomous (computer) agents coordinating their actions through the use of a communication protocol.
Most prototypically, this would apply to a team of autonomous robots working together but could also include situations like self-driving cars on the road (illustrated in \Cref{fig:self-driving}) or IoT devices on a local area network.
The two typical approaches to developing multi-agent communication protocols are handcrafting them or learning them like a latent variable between agents.
Handcrafted protocols (e.g., DHCP for network configuration) are typically well-suited for specific tasks but are also require significant expert design, which hinders much potential for open-domain or general purpose communication.
Automatically learned continuous protocols (i.e., messages are learned continuous vectors) solve some of these issues but raise new issues related to deep, learned representations such as low interpretability.
This task is distinct from autonomous agents communicating directly with humans, which we discuss in \Cref{sec:rev-interacting-humans}.

\begin{figure}
  \centering
  \def\figwidth{0.45\textwidth}
  \begin{subfigure}[t]{\figwidth}
    \centering
    \setlength{\fboxsep}{0pt}
    \fbox{
      \includegraphicsreview[height=5cm]{assets/driving-simple}
    }
    \caption{Complex scenario with various kinds of agents.}
  \end{subfigure}
  \begin{subfigure}[t]{\figwidth}
    \centering
    \includegraphicsreview[width=\linewidth]{assets/driving-realistic}
    \caption{Pixel-based input to approximate real-world diversity in observations.}
  \end{subfigure}
  \caption{%
    Self-driving vehicles in complex traffic situations are an important application of multi-agent communication.
    Diversity in both scenarios as well as the observations themselves indicate that open-ended communication systems could be more appropriate than handcrafted protocols where all scenarios are anticipated ahead of time.
    Screenshots from documentation of MetaDrive \citep{li2023metadrive} (Apache-2.0 license).
  }
  \unskip\label{fig:self-driving}
\end{figure}

\paragraph{Applicability}
Emergent communication addresses these issues in three main ways.
First, emergent communication is scalable to more general-purpose tasks since it is developed by computational processes directly from the functional pressures of the task it is applied to.
Second, it is more interpretable insofar as it resembles the structure of human language, for example, using discrete symbols in its communication channel or having a hierarchical syntactic structure (cf.\@  continuous vectors which do not resemble human language and require mathematical transformation to be analyzed).
Finally, human language is the gold standard for communication protocols insofar as it can apply to previously unseen situations and is robust to noise and other hindering factors.
Thus, developing communication protocols which deliberately mimic the structural properties of human language could be a way to better attain these desirable functional properties.

For example, the following design elements of an emergent communication system could contribute to recreating some of the above desirable properties of an emergent language.
To encourage general purpose language, we can start with an open world, open-ended environment (e.g., Minecraft) and/or one with many distinct situations (e.g., Starcraft, Dota 2).
Furthermore, tasks which have adversarial components can especially elicit a diversity of situations since one team of agents is constantly trying innovate to outcompete the other.
Towards interpretability, the agents could be constrained to communicate only with discrete symbols at human-scales (e.g., modest vocabulary size and message length).
Finally, elements like communication channel noise or constantly cycling out agents in the population can induce a more robust communication protocol since agents cannot as easily overfit to each other.


\paragraph{Current state}
Work on developing multi-agent communication protocols has experimented with a handful of environments and scenarios but has not established any one task as being definitively helped by emergent communication.
Many of the explored environments are a variation on
    navigation \citep{mul2019mastering,Li2022LearningED,masquil2022intrinsically}
    or the signalling game \citep{bullard2021quasi,cope2021learning,wang2022emergence,Tucker2021EmergentDC},
    although some include more abstract environments like a coalition-based voting game \citep{Li2022LearningED} or semantic communication \citep{thomas2022neuro}.
Emergent communication for multi-agent communication has been compared against competing methods, that is, handcrafted protocols \citep{Gupta2020NetworkedMR,Chen2022DeepRL} and learned continuous communication \citep{Li2022LearningED,wang2022emergence}.
  Although, these comparisons use the competing methods more as ``baseline points of reference'' rather than comparing them ``head-to-head'', where both methods are presented in their strongest forms so as to show the real-world superiority of emergent language-based communication.
In most cases, increasing the performance of the multi-agent team is the primary interest of the experiments; additionally, papers have also looked at emergent communication's robustness to corruption and noise \citep{cope2021learning,wang2022emergence} as well as the potential for communicating with partners not seen during training \citep{bullard2021quasi,cope2021learning}.

\paragraph{Next steps}
The first direction of future work on emergent communication for multi-agent communication is to find a niche for emergent communication, that is, presenting a particular task where, in realistic conditions, emergent communication surpasses state of the art non-emergent approaches.
Although emergent communication has intuitive advantages (discussed above in ``Applicability''), it has yet to be shown in a real-world task.
This is a significantly more difficult task than what most of the current literature accomplishes: namely demonstrating a on small scale that multi-agent communication is possible with emergent communication techniques as a proof of concept.
Based on the particular advantages of emergent communication, such a task will likely have to be open-domain or demand continual adaptation, rendering hand-crafted protocols impractical, while also needing some element of interpretability, demonstrating an advantage over learned continuous communication.
This is a formidable task as presenting effective definitions of ``open-domain'' and ``interpretable'' require formalizing rather abstract notions.

In conjunction with this first direction, it will also be necessary to empirically verify the intuitions that (1) emergent communication is more interpretable than continuous communication, and (2) emergent communication's structural similarities to human language confer some actual functional benefit beyond continuous or unconstrained communication.
If these intuitions are well-founded, then it will greatly expand the potential applications of emergent communication in multi-agent systems.


\subsection{Interacting with humans}%
\label{sec:rev-interacting-humans}
\paragraph{Description}
A perennial goal of computer systems has been more naturally interacting and communicating with humans.
This is an incredibly difficult task due to the complexities of human communication ranging from nuanced syntax and semantics to pragmatics and conversational dynamics.
While deep learning methods have had good success learning syntax and decent success learning semantics, proficiency at the level of pragmatics is not yet present because these higher levels of language and communication tend to be more difficult to learn from purely from text through a language modeling objective.
This is demonstrated in \citet{instructgpt} by the fact that an InstructGPT model outperforms a GPT-3 model $100{\times}$ larger when it comes to following a human's instructions (as evaluated by humans).
They observe from this that the language modeling objective alone is misaligned with the objective of ``follow the user's instructions helpfully and safely''; for example, truthfulness is one dimension that is drastically increased by training on human feedback \citep{instructgpt}.
Even with extensive training with human feedback, models like ChatGPT still significantly diverge from humans when it comes to pragmatics and communication strategies \citep{qiu2023pragmatic,guo2023close}.
Thus, despite large language models' fluency, they do not naturally capture critical aspects of interacting with humans, and current methods of addressing it entail relying directly on human supervision \citep{instructgpt}.

This application primarily refers to methods of interactively communicating in tasks like dialogue or human-robot collaboration.
We distinguish this from creating explainable machine learning models which we address in \Cref{sec:rev-explainable-models}.

\paragraph{Applicability}
The central argument for using emergent communication to better communicate with humans comes from the fact that an emergent communication agents naturally develop competency with a wide range of linguistic phenomena.
The hypothesis here is that the same functional pressures that drive the pragmatic and social aspects of human language could be replicated by sufficiently rich and embodied emergent communication environments.
Thus, the emergent communication agents could not only develop the syntax and semantics of the language but also pragmatic elements in response to the environmental and social pressures.
In fact, \citet{bisk-etal-2020-experience} argue that embodiment and interaction, beyond simply modeling static corpora, are necessary for learning to use the full depth of language.
Emergent communication, then, could be a more compute-driven (and less human-feedback intensive) way of imbuing machine learning models with a full range of linguistic competency that is necessary for seamlessly interacting with humans.


\paragraph{Current state}
Communicating with humans is an oft-cited potential application of emergent communication techniques, although few papers have directly experimented with it.
The papers we found in the survey were proof-of-concept tasks which demonstrated some possible methods for emergent communication agents interacting with humans.
One of the characteristic design choices of each paper is deciding how to structure the communication channel between the human and agents.

\begin{figure}
  \begin{subfigure}[t]{0.65\textwidth}
    \centering
    \includegraphicsreview[height=4cm]{assets/user-interface}
    \caption{User interface for interpreting the meaning of an emergent communication method from a visualization of the message's embedding \citep{Tucker2021EmergentDC}.}
    \unskip\label{fig:embed}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{0.30\textwidth}
    \centering
    \includegraphicsreview[height=3cm]{assets/sketch}
    \caption{Example of a ``message'' from a sketch-based game (from documentation of \citet{mihai2021learning}'s code).}
    \unskip\label{fig:sketch}
  \end{subfigure}
  \caption{Two examples of agent-to-human emergent communication interfaces.}
\end{figure}

For the direction of human-to-agent communication, \citet{Tucker2021EmergentDC} map natural language to a joint embedding space with the emergent language, making the embedded natural language understandable to the agents.
\citet{Li2022LearningED} have humans select embeddings directly from a labelled visualization of the embeddings (i.e., t-SNE) of emergent language messages.
For the direction of agent-to-human communication, \citet{Tucker2021EmergentDC} visualize the embedding of agent messages in a labelled embedding space, allowing a human to determine which cluster of messages an unlabelled message belongs to (shown in \Cref{fig:embed}).
\citet{mihai2021learning} show the human directly with a ``message'' (i.e., sketch) in a sketch-based signalling game (shown in \Cref{fig:sketch}).
Apart from direct human-agent interaction, \citet{Tucker2022GeneralizationAT} demonstrate machine translation-based approach where human and emergent languages are aligned through an image captioning task.

\paragraph{Next steps}
The first direction for using emergent communication to augment human-computer interaction is to determine the most the natural and scalable methods and modalities for human and computers to communicate.
The existing literature uses a handful of methods some of which are either unnatural and not scalable to more complex communication (e.g., interacting with concept/word embeddings).
Work on non-emergent human-computer interaction can inform emergent communication research not only on methods of communication but also concerning what environments would have the potential for complex communication while still being simple enough to work with.
For example, \citet{narayanchen2019collaborative} present a collaborative building game in a Minecraft environment which could satisfy these criteria.

The second direction for this application is empirically demonstrating the intuitive advantages of emergent communication over more established methods for human-computer interactions.
The pragmatics of interacting with humans is one of the areas with the most potential because pragmatics are inherently flexible, tied to extra-linguistic knowledge, and are more difficult to formalize than, say, syntax or semantics.
Nevertheless, emergent communication could help in the more difficult regions of syntax and semantics, such as disambiguating utterances which rely on contextual knowledge or common sense reasoning.


\subsection{Explainable machine learning models}%
\label{sec:rev-explainable-models}
\paragraph{Description}
Explainable machine learning models are those which can communicate to humans the reasons or factors behind a certain their decision.
Such model are a response to deep, black-box neural models which may be able to make accurate decisions but often for opaque or seemingly arbitrary reasons.
Instead it is desirable for explanations to be:
  (1) causally related to actual decision that is made (i.e., not a \emph{post hoc} rationalization);
  (2) expressed natural language, which is one of the most effective ways to convey ideas to humans;
  and (3) not impose a significant negative impact on the performance of the model.

Two paradigms of explainable machine learning models illustrate solutions only satisfying some of the criteria.
The first paradigm is using language generation models to generate explanations based on the hidden states of a model; while this permits the use of deep neural models, the explanations are decoupled from the actual decision since the explanation is superfluous with respect to the actual decision.
The second paradigm is using explicit, interpretable steps in reasoning to the prediction (e.g., decision trees, knowledge graphs); although these explanations are now causally efficacious with respect to the prediction, it restricts the complexity of model that can be used to make the prediction.
While the explanations these models generate are intrinsically related to the decisions made (e.g., the weights of a regression both explain the decision and cause it), they restrict the complexity of the model, and hence, can hamper overall performance.


\emph{Explainable machine learning models}, in some sense, is a subclass of \fullref{sec:rev-interacting-humans}; here the interaction is always focused on a machine learning model communicating accurate and interpretable explanations for its decision or behavior.


\paragraph{Applicability}
Emergent communication takes a radical approach to both the causal efficacy and the natural language aspect of explainable models.
To illustrate this, we can describe a ``deliberative ensemble of emergent communication agents''.
Such an ensemble would be posed a semi-adversarial game where first each member of the ensemble would generate an output for a given input.
After this, the ensemble members would communicate in the emergent language to try to convince the other members of the particular output before aggregating the members' revised decisions.
Given that emergent language is designed to resemble human language, the representation mismatch between natural language and the emergent language discourse is far less than natural language and the activations of a monolithic neural network.
Furthermore, since the deliberation and communication among agents is critical in the final decision of the ensemble, the explanation has a direct causal link to the decision.


\paragraph{Current state}
Using emergent communication for creating explainable machine learning models has only seen proof-of-concept exploration in one series of papers.
Namely, \citet{santamaria2020towards,chowdhury2020escell,chowdhury2020symbolic,chowdhury2020emergent} implement and experiment with a medical image classification model which, internally, is a Lewis signalling game \citep{lewis1970ConventionAP}.
This means that the internal representations are themselves the discrete messages of an emergent language.
Messages-as-internal representations, here, are intended to be a more natural modality for human working with the system than, for example, the activations of intermediate layers in the neural network.


\paragraph{Next steps}
The first direction for using emergent communication for explainable machine learning models is exploring methods of generating explanations beyond the signalling game that we see in the current literature.
The signalling game, while providing potentially interpretable messages, does not effectively exhibit the multi-step reasoning which
    (1) is most suited to the complex decisions which we would want explained,
    (2) is how humans generally explain themselves,
    and (3) is where emergent communication has the greatest potential to surpass more established methods.
Such games or environments might incorporate incentives for agents to collaborate and reason sequentially using the emergent language.
This reasoning process would then double as the basis for the decision and the explanation of the decision.

The second direction is incorporating state-of-the-art models into the emergent communication systems.
This application, more so than others, requires that the emergent communication-based model perform comparably on downstream tasks to more established explainable machine learning models;
  even if the emergent communication-based models are highly explainable, they are of little practical use if they are not comparable in performance to traditional approaches.
Given the size of current state-of-the-art models and inherent difficulty of training emergent communication models, this incorporation, in the near term, would likely be limited to leveraging pre-trained models which could be, at most, finetuned.
